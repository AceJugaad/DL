{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMIYmc5wXi0Y1n3kxnhaqmZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":16,"metadata":{"id":"gNqdm1kKyc9S","executionInfo":{"status":"ok","timestamp":1688707802881,"user_tz":-330,"elapsed":626,"user":{"displayName":"akshay naykodi","userId":"02708128421628216378"}}},"outputs":[],"source":["import nltk\n","\n"]},{"cell_type":"code","source":["nltk.download(\"punkt\")\n","nltk.download('words')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6DCyUsN0ueY","executionInfo":{"status":"ok","timestamp":1688707807874,"user_tz":-330,"elapsed":688,"user":{"displayName":"akshay naykodi","userId":"02708128421628216378"}},"outputId":"edbcc8ce-1006-4046-88fb-0087423329c5"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["from nltk import tokenize\n","para = \"Hello! My name is Pritesh. Today you'll be learning NLTK.\"\n","sents = tokenize.sent_tokenize(para)\n","print(\"\\nsentence tokenization\\n===================\\n\",sents)\n","# word tokenization\n","print(\"\\nword tokenization\\n===================\\n\")\n","for index in range(len(sents)):\n"," words = tokenize.word_tokenize(sents[index])\n","print(words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWG-iMXk0tFx","executionInfo":{"status":"ok","timestamp":1688707811750,"user_tz":-330,"elapsed":412,"user":{"displayName":"akshay naykodi","userId":"02708128421628216378"}},"outputId":"92443c99-eb16-40be-9cac-1607b9962f9b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","sentence tokenization\n","===================\n"," ['Hello!', 'My name is Pritesh.', \"Today you'll be learning NLTK.\"]\n","\n","word tokenization\n","===================\n","\n","['Today', 'you', \"'ll\", 'be', 'learning', 'NLTK', '.']\n"]}]}]}