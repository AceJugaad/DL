{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oa95PBWkJPC",
        "outputId": "dae9a296-b59d-46a7-f2c9-f3347afd2eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "sentence tokenization\n",
            "===================\n",
            " ['Hello!', 'My name is Pritesh.', \"Today you'll be learning NLTK.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk import tag\n",
        "from nltk import chunk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "para = \"Hello! My name is Pritesh. Today you'll be learning NLTK.\"\n",
        "sents =tokenize.sent_tokenize(para)\n",
        "print(\"\\nsentence tokenization\\n===================\\n\",sents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nword tokenization\\n===================\\n\")\n",
        "for index in range(len(sents)):\n",
        "    words = tokenize.word_tokenize(sents[index])\n",
        "    print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZktB6HllGh-",
        "outputId": "fe0d7630-02b4-4821-8bcd-a993ed1178a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "word tokenization\n",
            "===================\n",
            "\n",
            "['Hello', '!']\n",
            "['My', 'name', 'is', 'Pritesh', '.']\n",
            "['Today', 'you', \"'ll\", 'be', 'learning', 'NLTK', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = []\n",
        "for index in range(len(sents)):\n",
        "    tagged_words.append(tag.pos_tag(words))\n",
        "print(\"\\nPOS Tagging\\n===========\\n\",tagged_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKsAGcXqlLuT",
        "outputId": "2289d914-6a39-411e-8729-827f7c34d8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "POS Tagging\n",
            "===========\n",
            " [[('Today', 'NN'), ('you', 'PRP'), (\"'ll\", 'MD'), ('be', 'VB'), ('learning', 'VBG'), ('NLTK', 'NNP'), ('.', '.')], [('Today', 'NN'), ('you', 'PRP'), (\"'ll\", 'MD'), ('be', 'VB'), ('learning', 'VBG'), ('NLTK', 'NNP'), ('.', '.')], [('Today', 'NN'), ('you', 'PRP'), (\"'ll\", 'MD'), ('be', 'VB'), ('learning', 'VBG'), ('NLTK', 'NNP'), ('.', '.')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = []\n",
        "for index in range(len(sents)):\n",
        "    tree.append(chunk.ne_chunk(tagged_words[index]))\n",
        "print(\"\\nchunking\\n========\\n\")\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3JLWbzplPxL",
        "outputId": "78014c28-89c3-494e-8ebb-f214b3d52076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "chunking\n",
            "========\n",
            "\n",
            "[Tree('S', [('Today', 'NN'), ('you', 'PRP'), (\"'ll\", 'MD'), ('be', 'VB'), ('learning', 'VBG'), Tree('ORGANIZATION', [('NLTK', 'NNP')]), ('.', '.')]), Tree('S', [('Today', 'NN'), ('you', 'PRP'), (\"'ll\", 'MD'), ('be', 'VB'), ('learning', 'VBG'), Tree('ORGANIZATION', [('NLTK', 'NNP')]), ('.', '.')]), Tree('S', [('Today', 'NN'), ('you', 'PRP'), (\"'ll\", 'MD'), ('be', 'VB'), ('learning', 'VBG'), Tree('ORGANIZATION', [('NLTK', 'NNP')]), ('.', '.')])]\n"
          ]
        }
      ]
    }
  ]
}